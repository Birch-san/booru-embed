{
  // Use IntelliSense to learn about possible attributes.
  // Hover to view descriptions of existing attributes.
  // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Python: TSV Tokenizer",
      "type": "python",
      "request": "launch",
      "module": "script.tsv_tokenizer",
      "justMyCode": true
    },
    {
      "name": "Python: TSV Bucketer",
      "type": "python",
      "request": "launch",
      "module": "script.tsv_bucketer",
      "justMyCode": true
    },
    {
      "name": "Python: Make tokenizer",
      "type": "python",
      "request": "launch",
      "module": "script.make_tokenizer",
      "justMyCode": true
    },
    {
      "name": "Python: Read bucket",
      "type": "python",
      "request": "launch",
      "module": "script.read_bucket",
      "justMyCode": true
    },
    {
      "name": "Python: T5 MLM Flax",
      "type": "python",
      "request": "launch",
      "module": "script.run_t5_mlm_flax",
      "justMyCode": false,
      "args": [
        "--output_dir", "./out-t5-mlm-flax",
        "--model_type", "t5",
        "--config_name", "google/t5-v1_1-small",
        "--tokenizer_name", "google/t5-v1_1-small",
        "--use_fast_tokenizer", "True",
        // "--dataset_name", "oscar",
        "--dataset_name", "ArtifactAI/arxiv-math-instruct-50k",
        // "--dataset_config_name", "unshuffled_deduplicated_en",
        "--max_seq_length", "512",
        "--per_device_train_batch_size", "32",
        "--per_device_eval_batch_size", "32",
        "--adafactor",
        "--learning_rate", "0.005",
        "--weight_decay", "0.001",
        "--warmup_steps", "2000",
        "--overwrite_output_dir",
        "--logging_steps", "500",
        "--save_steps", "10000",
        "--eval_steps", "2500",
        // "--push_to_hub"
      ]
    },
    {
      "name": "Python: T5 MLM Torch",
      "type": "python",
      "request": "launch",
      "module": "script.run_t5_mlm_torch",
      "justMyCode": false,
      "args": [
        "--output_dir", "./out-t5-mlm-torch",
        "--model_type", "t5",
        "--config_name", "google/t5-v1_1-small",
        "--tokenizer_name", "google/t5-v1_1-small",
        "--use_fast_tokenizer", "True",
        // "--dataset_name", "oscar",
        "--dataset_name", "ArtifactAI/arxiv-math-instruct-50k",
        // "--dataset_config_name", "unshuffled_deduplicated_en",
        "--max_seq_length", "512",
        "--per_device_train_batch_size", "32",
        "--per_device_eval_batch_size", "32",
        "--adafactor",
        "--learning_rate", "0.005",
        "--weight_decay", "0.001",
        "--warmup_steps", "2000",
        "--overwrite_output_dir",
        "--logging_steps", "500",
        "--save_steps", "10000",
        "--eval_steps", "2500",
        // "--push_to_hub"
      ]
    },
    {
      "name": "Python: MLM Torch",
      "type": "python",
      "request": "launch",
      "module": "script.run_mlm_torch",
      "justMyCode": false,
      "args": [
        "--model_name_or_path", "roberta-base",
        "--dataset_name", "ArtifactAI/arxiv-math-instruct-50k",
        // "--dataset_name", "wikitext",
        // "--dataset_config_name", "wikitext-2-raw-v1",
        "--per_device_train_batch_size", "8",
        "--per_device_eval_batch_size", "8",
        "--do_train",
        // "--do_eval",
        "--output_dir", "./out-mlm-torch",
        "--overwrite_output_dir",
      ]
    },
    {
      "name": "Python: MLM Torch (no trainer)",
      "type": "python",
      "request": "launch",
      "module": "script.run_mlm_torch_no_trainer",
      "justMyCode": false,
      "args": [
        "--model_name_or_path", "roberta-base",
        "--dataset_name", "ArtifactAI/arxiv-math-instruct-50k",
        // "--dataset_name", "wikitext",
        // "--dataset_config_name", "wikitext-2-raw-v1",
        "--per_device_train_batch_size", "8",
        "--per_device_eval_batch_size", "8",
        "--output_dir", "./out-mlm-torch-no-trainer",
      ]
    },
    {
      "name": "Python: T5 MLM Torch 2",
      "type": "python",
      "request": "launch",
      "module": "script.run_t5_mlm_torch_2",
      "justMyCode": false,
      "args": [
        // "--model_name_or_path", "roberta-base",
        "--config_name", "google/t5-v1_1-small",
        "--tokenizer_name", "google/t5-v1_1-small",
        "--dataset_name", "ArtifactAI/arxiv-math-instruct-50k",
        // "--dataset_name", "wikitext",
        // "--dataset_config_name", "wikitext-2-raw-v1",
        "--per_device_train_batch_size", "8",
        "--per_device_eval_batch_size", "8",
        "--do_train",
        // "--do_eval",
        "--output_dir", "./out-t5-mlm-torch-2",
        "--overwrite_output_dir",
      ]
    },
    {
      "name": "Python: T5 MLM Torch Booru",
      "type": "python",
      "request": "launch",
      "module": "script.run_t5_mlm_torch_booru",
      "justMyCode": false,
      "args": [
        "--config_name", "./src/model/config/t5-booru-small",
        "--tokenizer_name", "google/t5-v1_1-small",
        "--per_device_train_batch_size", "128",
        // "--per_device_train_batch_size", "8",
        "--per_device_eval_batch_size", "4",
        "--do_train",
        "--output_dir", "./out-t5-mlm-torch-booru",
        "--overwrite_output_dir",
        "--xformers",
        "--gradient_checkpointing",
        // "--log_flops",
        // "--log_memory",
        // "--report_to", "none",
        "--report_to", "wandb",
        // "--optim", "adamw_8bit",
        "--optim", "sgd",
        "--use_lars",
        "--sgd_momentum", "0.9",
        "--log_every_n_steps", "5",
        "--collator_device", "cpu",
        "--pad_to_multiple", "8",
        "--num_train_epochs", "1", // just doing this for now to speed up lr schedule
        // self.args.warmup_steps
        // self.args.warmup_ratio
        // num_examples=5_626_898
        // len_dataloader=703_363 (it's num_examples // batch_size:=8)
        // num_update_steps_per_epoch=703_363 (it's len_dataloader)
        // TODO: max length OOMs at 192, but 128 is fine
        // "--pad_to_max_length",
        // "--replay_collator",
        // TODO: --pad_to_max_seq_len, for better torch compile
        // TODO: full torch compile?
        // TODO: measure speed with no-op model and no-op dataloader
        // "--torch_compile",
        // "--torch_compile_mode", "reduce-overhead", // https://pytorch.org/docs/stable/generated/torch.compile.html
        // "--torch_compile_plan_b",
        // "--run_name", "batch_128_workers_1_cpu_maxlen_compile_fix",
        // "learning_rate", ".00005", // 5e-5 == .00005 // default
        "--learning_rate", "1e-1", // 1e-4 == .0001
        "--run_name", "batch_128_sreparam_static_lars_1e-1",
        // "--dataloader_num_workers", "1"
      ],
      "env": {
        "ACCELERATE_MIXED_PRECISION": "bf16",
        // "CUDA_LAUNCH_BLOCKING": "1",
      }
      // note: fastest seemed to be non-xformers, with single-precision. yikes.
      // batch 128 possible with xformers + mixed. 23371MiB / 24564MiB, reached iteration 255 and beyond
      // batch 128 also possible with sdp + mixed. 22921MiB / 24564MiB, though by iteration 150 was 24101MiB. made it to 255
      // need to compare iteration speed somehow. and determine which xformers kernel was used.
      // could try gradient checkpointing to trade iteration speed for batch size
      // could try more dataloader workers to alleviate iteration bottleneck
      // still got some loss masking to do
      // batch 128 mixed bf16 without xformers OOMed on iteration 49. depends on random luck I think.
      // gradient checkpointing reduces memory to 11403MiB, still batch size 128 xformers mixed, still >3it/s
    },
    {
      "name": "Python: Test checkpoint",
      "type": "python",
      "request": "launch",
      "module": "script.test_checkpoint",
      "justMyCode": false,
      "args": [
        "--output_dir", "./out-t5-mlm-torch-booru",
        "--model_name_or_path", "./out-sreparam-fix/checkpoint-1000",
        // "--xformers",
        // "--pad_to_multiple", "8",
        "--per_device_eval_batch_size", "8",
      ]
    },
    {
      "name": "Python: Loss benchmark",
      "type": "python",
      "request": "launch",
      "module": "script.loss_bench",
      "justMyCode": false
    }
  ]
}